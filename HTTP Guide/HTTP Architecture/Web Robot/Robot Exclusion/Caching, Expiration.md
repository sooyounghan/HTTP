-----
### robots.txt의 캐싱과 만료
-----
1. 매 파일 접근마다 로봇이 robots.txt 파일을 새롭게 가져와야 한다면, 이는 로봇을 덜 효율적으로 만들 뿐 아니라 웹 서버의 부하도 두 배로 늘렸을 것
2. 대신 로봇은 주기적으로 robots.txt를 가져와서 그 결과를 캐시해야 함
3. robots.txt의 캐시된 사본은 robots.txt 파일이 만료될 때까지 로봇에 의해 사용
4. robots.txt 파일의 캐싱을 제어하기 위해 표준 HTTP 캐시 제어 메커니즘이 원 서버와 로봇 양쪽 모두에 의해 사용
   - 로봇은 HTTP 응답의 Cache-Control과 Expires 헤더에 주의를 기울여야 함
5. 오늘날 많은 크롤러 제품들은 HTTP/1.1 클라이언트가 아니므로, 웹 마스터들은 이 크롤러들이 robots.txt 리소스에 적용되는 캐시 지시자를 이해 못할 수 있음
6. 로봇 명세 초안은 Cache-Control 지시자가 존재하는 경우 7일 간 캐싱하도록 하고 있음
   - 실무에서는 너무 길며, 만약 robtos.txt 파일이 없는 상태가 1주일 동안 캐시되면, 새로 만들어진 robots.txt 파일은 아무런 효과가 없을 것
