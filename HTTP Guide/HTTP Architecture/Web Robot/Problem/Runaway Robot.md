-----
### 폭주하는 로봇
-----
1. 로봇은 웹 서핑을 하는 사람보다 훨씬 빠르게 HTTP 요청을 만들 수 있으며, 흔히 빠른 네트워크 연결을 갖춘 빠른 컴퓨터 위에서 동작
2. 만약 로봇이 논리적인 에러를 갖고 있거나 순환에 빠졌다면, 웹 서버에 극심한 부하를 안겨줄 수 있으며, 서버에 과부하를 유발해 다른 누구에게도 서비스를 못하게 만드는 일도 있을 수 있음
3. 따라서, 폭주 방지를 위한 보호 장치를 신경 써서 설계해야함
4. 오래된 URL
   - 몇몇 로봇은 URL 목록을 방문하지만, 그 목록은 오래되었을 수 있음
   - 만약 웹 사이트가 그들의 콘텐츠를 많이 바꾸었다면, 로봇들은 존재하지 않는 URL에 대한 요청을 많이 보낼 수 있음
   - 이는 존재하지 않는 문서에 대한 접근 요청으로 에러 로그가 채워지거나, 에러 페이지를 제공하는 부하로 인해 웹 서버의 요청에 대한 수용 능력이 감소됨

5. 길고 잘못된 URL
   - 순환이나 프로그래밍 상 오류로 인해 로봇은 웹 사이트에게 크고 의미 없는 URL을 요청할 수 있음
   - 만약, 그 URL이 충분히 길다면, 이는 웹 서버의 처리 능력에 영향을 주고, 웹 서버의 접근 로그를 어지럽게 채우고, 고장 유발 가능

6. 호기심이 지나친 로봇
   - 어떤 로봇들은 사적 데이터에 대한 URL을 얻어 그 데이터를 인터넷 검색 엔진이나 기타 애플리케이션을 통해 쉽게 접근할 수 있도록 만들 수 있음
   - 보통 사적 콘텐츠에 대한 이미 존재하는 하이퍼링크를 로봇이 따라감으로 벌어지는 일
   - 웹에서 많은 양의 데이터를 검색하는 로봇은 인터넷을 통해 접근하길 원치 않는 민감한 데이터를 검색할 수 있음에 주의헤야 하므로, 이러한 콘텐츠를 무시하는 메커니즘이 중요
   - 구글과 같은 일부 검색엔진들은 그들이 크롤링한 페이지들을 그대로 보관하므로, 콘텐츠가 제거되더라도 일정 시간 동안 여전히 검색되고 접근 가능

7. 동적 게이트웨이 접근
   - 로봇은 게이트웨이 애플리케이션 콘텐츠에 대한 URL로 요청할 수 있음
  
