-----
### 웹 사이트와 robots.txt 파일들
-----
1. 웹 사이트의 어떤 URL에 방문하기 전, 그 웹 사이트에 robots.txt 파일이 존재한다면, 로봇은 반드시 그 파일을 가져와서 처리해야 함
2. 호스트 명과 포트번호에 의해 정의되는 어떤 웹 사이트가 있을 떄, 그 사이트 전체에 대한 robots.txt 파일은 단 하나만 존재
   - 만약, 웹 사이트가 가상 호스팅된다면, 다른 모든 파일은 각각 가상 docroot에서 서로 다른 robots.txt가 존재할 수 있음

3. robots.txt 가져오기
   - 로봇은 웹 서버의 파일들과 마찬가지로 HTTP GET 메서드를 이용해 robots.txt 리소를 가져옴
   - 그 robots.txt가 존재하면, 서버는 그 파일을 text/plain 본문으로 반환
   - 💡 만약, 서버가 404 Not Found HTTP 상태 코드로 응답한다면, 로봇은 그 서버는 로봇의 접근을 제한하지 않는 것으로 간주하고 어떤 파일이든 요청
   - 로봇은 사이트 관리자가 로봇의 접근을 추적할 수 있도록 From이나 User-Agent 헤더를 통해 신원 정보를 넘기고, 사이트 관리자가 로봇에 대해 문의나 불만 사항을 있을 경우를 위해 연락처를 제공해야함
   - 상용 웹 로봇이 보낼 수 있는 HTTP 크롤러 요청의 예
<div align="center">
<img src="https://github.com/user-attachments/assets/6313ffa8-513c-4ec1-a574-a25e05cd91b7">
</div>

4. 응답 코드
   - 많은 웹 사이트가 robots.txt를 가지고 있지 않지만, 로봇은 그 사실을 모르며, 로봇은 어떤 웹 사이트든 반드시 robots.txt를 차음
   - 로봇은 robots.txt의 검색 결과에 따라 다르게 동작
     + 서버가 성공(HTTP 상태 코드 2XX)으로 응답하면, 로봇은 반드시 그 응답의 콘텐츠를 파싱하여 차단 규칙을 얻고, 그 사이트에서 무언가 가져오려 할 때 그 규칙을 따라야함
     + 만약 리소스가 존재하지 않는다고 서버가 응답(HTTP 상태 코드 404)하면, 로봇은 활성화된 차단 규칙이 존재하지 않는다고 robos.txt의 제약 없이 그 사이트에 접근할 수 있음
     + 만약 서버가 접근 제한(HTTP 상태 코드 401 혹은 403)으로 응답한다면 로봇은 그 사이트로의 접근은 완전히 제한되어 있다고 가정
     + 만약 요청 시도가 일시적 실패했다면(HTTP 상태 코드 503) 로봇은 그 사이트의 리소스를 검색하는 것은 뒤로 미뤄야 함
     + 만약 서버 응답이 리다이렉션을 의미한다면(HTTP 상태 코드 3XX) 로봇은 리소스가 발견될 때까지 리다이렉트를 따라가야 함
