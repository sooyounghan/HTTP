-----
### 로봇 차단하기
-----
1. 로봇 커뮤니티는 로봇에 의한 웹 사이트 접근이 유발할 수 있는 문제를 알고 있음
2. 1994년, 웹 마스터에게 로봇의 동작을 더 잘 제어할 수 있는 메커니즘을 제공하는 단순하고 자발적 기법 제안 : 이 표준은 Robots Exclusion Standard라고 이름을 지어짐
   - 로봇의 접근을 제어하는 정보를 저장하는 파일의 이름을 따서 robos.txt라고 불림

3. 아이디어
   - 어떤 웹 서버는 서버의 문서 루트에 robots.txt라고 이름 붙은 선택적 파일 제공 가능
   - 이 파일은 어떤 로봇이 서버의 어떠 부분에 접근할 수 있는지에 대한 정보가 담겨있음
   - 만약, 로봇이 이 자발적인 표준에 따른다면, 웹 사이트의 어떤 다른 리소스에 접근하기 위해 우선 그 사이트의 robots.txt를 요청
<div align="center">
<img src="https://github.com/user-attachments/assets/3cef92f6-a78a-4a74-b464-264c53c9aa1b">
</div>

   - 조의 하드웨어에서 ```http://www.joes-hardware/specials/acetylene-torches.html```을 다운받으려고 함
   - 하지만 로봇은 그 페이지를 요청하기 전 먼저 이 페이지를 가져올 수 있는 권한이 있는지 확인하기 위해 robots.txt 파일을 검사할 필요가 있음
   - 이 예에서, robots.txt 파일은 로봇을 차단하지 않으므로 로봇은 그 페이지를 가져올 수 있게 됨

