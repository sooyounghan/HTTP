------
### 방문한 곳 관리
-----
1. 방문한 곳을 지속적으로 추적하는 것은 쉽지 않음
2. 만약, 전 세계의 웹 콘텐츠의 상당 부분을 크롤링하려 한다면, 수십억 개의 URL을 방문할 준비가 필요할 것
   - 어떤 URL을 방문했는지 빠르게 판단하기 위해서는 복잡한 자료 구조를 사용할 필요가 있으며, 이 자료 구조는 속도와 메모리 사용 면에서 효과적이어야함
3. 수억 개의 URL은 빠른 검색 구조를 요구하므로 빠른 속도는 중요
   - URL 목록의 완벽한 검색은 불가능
   - 로봇은 어떤 URL이 방문했던 곳인지 빠르게 결정하기 위해 적어도 검색 트리나 해시 테이블을 필요로 할 것
4. 수억 개의 URL은 많은 공간을 차지하며, 만약 평균 URL이 40바이트 길이이고, 웹 로봇이 5억 개의 URL을 크롤링 했다면(웹의 일부에 불과), 검색 데이터 구조는 이 URL들을 유지하기 위해 20GB 이상 메모리 요구
5. 대규모 웹 크롤러가 그들이 방문한 곳을 관리하기 위해 사용하는 유용한 기법
   - 트리와 해시 테이블 : 복잡한 로봇이라면 방문한 URL을 추적하기 위해 검색 트리나 해시 테이블 사용 (URL을 훨씬 빨리 찾아볼 수 있게 해주는 소프트웨어 자료 구조)
   - 느슨한 존재 비트맵 : 공간 사용을 최소화하기 위해, 몇몇 대규모 크롤러들은 존재 비트 배열(Presence Bit Array)과 같은 느슨한 자료 구조를 사용하며, 각 URL은 해시 함수에 의해 고정된 크기의 숫자로 변환되고, 배열 안에 대응하는 존재 비트(Presence Bit)를 가짐
     + URL이 크롤링 되었을 때, 해당하는 존재 비트가 만들어지며, 만약 존재 비트가 이미 존재한다면, 크롤러는 그 URL을 이미 크롤링 되었다고 간주
     + URL의 개수는 잠재적으로 무한한 데 반해, 존재 비트 배열에는 유한한 개수의 비트만이 존재하므로 같은 존재 비트에 두 URL이 매핑되어 충돌할 잠재적 가능성 존재
     + 크롤러는 크롤링한 적 없는 페이지를 크롤링했다고 잘못 판단할 것이며, 큰 존재 비트를 사용해 이런 일이 거의 일어나지 않도록 할 수 있음 : 충돌로 인한 패널티는 페이지 하나가 크롤링에서 제외되는 것

   - 체크 포인트 : 로봇 프로그램이 갑작스럽게 중단될 경우를 대비해, 방문할 URL의 목록이 디스크에 저장되었는지 확인
   - 파티셔닝 : 웹이 성장하면서, 한 대의 컴퓨터에서 하나의 로봇이 크롤링을 완수하는 것은 불가능
     + 크롤링을 완수하기엔 한 대의 컴퓨터로는 메모리, 디스크 공간, 연산 능력, 네트워크 대역폭이 충분하지 못할 수 있음
     + 몇몇 대규모 웹 로봇은, 각각이 분리된 한 대의 컴퓨터인 로봇들이 동시에 일하고 있는 농장(Farm)을 이용
     + 각 로봇엔 URL들의 특정 한 부분이 할당되어 그에 대한 책임을 지며, 로봇들은 서로 도와 웹을 크롤링
     + 개별 로봇들은 URL을 이리저리 넘겨주고너, 오동작하는 동료를 도와주거나, 혹은 그 외 이유로 그들의 활동을 조정하기 위해 커뮤니케이션 할 필요가 있음
